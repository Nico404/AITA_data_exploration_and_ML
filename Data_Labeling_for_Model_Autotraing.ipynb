{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "54deaa46",
   "metadata": {},
   "source": [
    "This notebook is the next step after scrapping posts and comments from the subreddit r/AITA and analysing the data collected & trying applying our first Text Classification: <br />\n",
    "https://github.com/Nico404/scrap_reddit <br />\n",
    "https://github.com/Nico404/AITA_data_exploration_and_ML/blob/master/AITA_data_exploration.ipynb <br /> \n",
    "https://github.com/Nico404/AITA_data_exploration_and_ML/blob/master/Zero_shot_model.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fba82dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from transformers import pipeline\n",
    "verbose=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6b952ea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>post_content</th>\n",
       "      <th>post_title</th>\n",
       "      <th>verdict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10uxee0</td>\n",
       "      <td>I know this post sounds super petty, but this ...</td>\n",
       "      <td>AITA for telling my boyfriend I'll shave my le...</td>\n",
       "      <td>NTA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10ur722</td>\n",
       "      <td>My daughter Bryn F9 is going on a trip to a ne...</td>\n",
       "      <td>AITA for pulling my daughter from a waterpark ...</td>\n",
       "      <td>NTA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10upxdd</td>\n",
       "      <td>Alright so my son (17) has weekly therapy appo...</td>\n",
       "      <td>AITA for not letting an elderly woman have my ...</td>\n",
       "      <td>NTA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10v2vra</td>\n",
       "      <td>We live three blocks away from my parents and ...</td>\n",
       "      <td>AITA for taking my kids to my parents house to...</td>\n",
       "      <td>NTA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10ung90</td>\n",
       "      <td>My daughter (16) and I have gotten into a mass...</td>\n",
       "      <td>AITA for calling my daughter a selfish insecur...</td>\n",
       "      <td>NTA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3502</th>\n",
       "      <td>1128lsq</td>\n",
       "      <td>So I am 21F, my friend \"Sasha\" is 20F and her ...</td>\n",
       "      <td>AITA for telling my friend I don't like her si...</td>\n",
       "      <td>YTA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3503</th>\n",
       "      <td>1123c1c</td>\n",
       "      <td>On Saturday, me and one of my best friends wer...</td>\n",
       "      <td>AITA for rolling my eyes at my friend?</td>\n",
       "      <td>NTA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3504</th>\n",
       "      <td>1122vfk</td>\n",
       "      <td>(English is not my native language) So, a bit ...</td>\n",
       "      <td>AITA for not signing my daughter in for a ches...</td>\n",
       "      <td>YTA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3505</th>\n",
       "      <td>1122rza</td>\n",
       "      <td>Derek (25M, fake name obvs) is my (25M) best f...</td>\n",
       "      <td>AITA for calling my friend's gf a jealous b wo...</td>\n",
       "      <td>YTA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3506</th>\n",
       "      <td>1122ahq</td>\n",
       "      <td>Quick backstory:My dad had an eye surgery gone...</td>\n",
       "      <td>WIBTA if I stop giving my dad money until he s...</td>\n",
       "      <td>NTA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3507 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      post_id                                       post_content  \\\n",
       "0     10uxee0  I know this post sounds super petty, but this ...   \n",
       "1     10ur722  My daughter Bryn F9 is going on a trip to a ne...   \n",
       "2     10upxdd  Alright so my son (17) has weekly therapy appo...   \n",
       "3     10v2vra  We live three blocks away from my parents and ...   \n",
       "4     10ung90  My daughter (16) and I have gotten into a mass...   \n",
       "...       ...                                                ...   \n",
       "3502  1128lsq  So I am 21F, my friend \"Sasha\" is 20F and her ...   \n",
       "3503  1123c1c  On Saturday, me and one of my best friends wer...   \n",
       "3504  1122vfk  (English is not my native language) So, a bit ...   \n",
       "3505  1122rza  Derek (25M, fake name obvs) is my (25M) best f...   \n",
       "3506  1122ahq  Quick backstory:My dad had an eye surgery gone...   \n",
       "\n",
       "                                             post_title verdict  \n",
       "0     AITA for telling my boyfriend I'll shave my le...     NTA  \n",
       "1     AITA for pulling my daughter from a waterpark ...     NTA  \n",
       "2     AITA for not letting an elderly woman have my ...     NTA  \n",
       "3     AITA for taking my kids to my parents house to...     NTA  \n",
       "4     AITA for calling my daughter a selfish insecur...     NTA  \n",
       "...                                                 ...     ...  \n",
       "3502  AITA for telling my friend I don't like her si...     YTA  \n",
       "3503             AITA for rolling my eyes at my friend?     NTA  \n",
       "3504  AITA for not signing my daughter in for a ches...     YTA  \n",
       "3505  AITA for calling my friend's gf a jealous b wo...     YTA  \n",
       "3506  WIBTA if I stop giving my dad money until he s...     NTA  \n",
       "\n",
       "[3507 rows x 4 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data from AITA_data_exploration.ipynb\n",
    "with open('data/pickled_post_data.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "posts_df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "posts_df[\"verdict\"] = posts_df[\"comment_results\"].apply(lambda x: max(x, key=x.get))\n",
    "\n",
    "posts_df = posts_df.drop(\"comment_results\", axis=1)\n",
    "posts_df\n",
    "\n",
    "# let's keep it at 3K rows since it's the AutoTrain limit for free usage \n",
    "posts_df.to_csv(\"data/AITA_labeled_posts.csv\", index=False)\n",
    "posts_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474cec6a",
   "metadata": {},
   "source": [
    "Let's upload our dataset to Hugging Face\n",
    "https://huggingface.co/datasets/nicoco404/AITA_labeled_posts\n",
    "\n",
    "Now let's create a new autotrain project - Text Classification (Multi-class)\n",
    "https://ui.autotrain.huggingface.co/new\n",
    "\n",
    "We'll use <b>post_content</b> as text input, and <b>verdict</b> as the target and launch the AutoTrain. \n",
    "Free evaluation will run and compare 5 models on 3K lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a79f692b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model ID</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision macro</th>\n",
       "      <th>Precision micro</th>\n",
       "      <th>Precision weighted</th>\n",
       "      <th>Recall macro</th>\n",
       "      <th>Recall micro</th>\n",
       "      <th>Recall weighted</th>\n",
       "      <th>F1 macro</th>\n",
       "      <th>F1 micro</th>\n",
       "      <th>F1 weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#3535895495 putrid-cormorant</td>\n",
       "      <td>0.7609</td>\n",
       "      <td>0.7628</td>\n",
       "      <td>0.1092</td>\n",
       "      <td>0.7628</td>\n",
       "      <td>0.5829</td>\n",
       "      <td>0.1429</td>\n",
       "      <td>0.7628</td>\n",
       "      <td>0.7628</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.7628</td>\n",
       "      <td>0.6608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#3535895498 idiotic-lyrebird</td>\n",
       "      <td>0.7623</td>\n",
       "      <td>0.7628</td>\n",
       "      <td>0.1805</td>\n",
       "      <td>0.7628</td>\n",
       "      <td>0.6687</td>\n",
       "      <td>0.1440</td>\n",
       "      <td>0.7628</td>\n",
       "      <td>0.7628</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>0.7628</td>\n",
       "      <td>0.6633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#3535895497 supportive-chamois</td>\n",
       "      <td>0.7666</td>\n",
       "      <td>0.7628</td>\n",
       "      <td>0.1090</td>\n",
       "      <td>0.7628</td>\n",
       "      <td>0.5819</td>\n",
       "      <td>0.1429</td>\n",
       "      <td>0.7628</td>\n",
       "      <td>0.7628</td>\n",
       "      <td>0.1236</td>\n",
       "      <td>0.7628</td>\n",
       "      <td>0.6602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#3535895496 ethical-peafowl</td>\n",
       "      <td>0.7741</td>\n",
       "      <td>0.7628</td>\n",
       "      <td>0.1090</td>\n",
       "      <td>0.7628</td>\n",
       "      <td>0.5819</td>\n",
       "      <td>0.1429</td>\n",
       "      <td>0.7628</td>\n",
       "      <td>0.7628</td>\n",
       "      <td>0.1236</td>\n",
       "      <td>0.7628</td>\n",
       "      <td>0.6602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#3535895499 juicy-weasel</td>\n",
       "      <td>0.7805</td>\n",
       "      <td>0.7628</td>\n",
       "      <td>0.1090</td>\n",
       "      <td>0.7628</td>\n",
       "      <td>0.5819</td>\n",
       "      <td>0.1429</td>\n",
       "      <td>0.7628</td>\n",
       "      <td>0.7628</td>\n",
       "      <td>0.1236</td>\n",
       "      <td>0.7628</td>\n",
       "      <td>0.6602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Model ID    Loss  Accuracy  Precision macro  \\\n",
       "0    #3535895495 putrid-cormorant  0.7609    0.7628           0.1092   \n",
       "1    #3535895498 idiotic-lyrebird  0.7623    0.7628           0.1805   \n",
       "2  #3535895497 supportive-chamois  0.7666    0.7628           0.1090   \n",
       "3     #3535895496 ethical-peafowl  0.7741    0.7628           0.1090   \n",
       "4        #3535895499 juicy-weasel  0.7805    0.7628           0.1090   \n",
       "\n",
       "   Precision micro  Precision weighted  Recall macro  Recall micro  \\\n",
       "0           0.7628              0.5829        0.1429        0.7628   \n",
       "1           0.7628              0.6687        0.1440        0.7628   \n",
       "2           0.7628              0.5819        0.1429        0.7628   \n",
       "3           0.7628              0.5819        0.1429        0.7628   \n",
       "4           0.7628              0.5819        0.1429        0.7628   \n",
       "\n",
       "   Recall weighted  F1 macro  F1 micro  F1 weighted  \n",
       "0           0.7628    0.1238    0.7628       0.6608  \n",
       "1           0.7628    0.1264    0.7628       0.6633  \n",
       "2           0.7628    0.1236    0.7628       0.6602  \n",
       "3           0.7628    0.1236    0.7628       0.6602  \n",
       "4           0.7628    0.1236    0.7628       0.6602  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_data = {'Model ID': ['#3535895495 putrid-cormorant', ' #3535895498 idiotic-lyrebird', '#3535895497 supportive-chamois', '#3535895496 ethical-peafowl', '#3535895499 juicy-weasel'],\n",
    "        'Loss': [0.7609, 0.7623, 0.7666, 0.7741, 0.7805],\n",
    "        'Accuracy': [0.7628, 0.7628, 0.7628, 0.7628, 0.7628],\n",
    "        'Precision macro': [0.1092, 0.1805, 0.1090, 0.1090, 0.1090],\n",
    "        'Precision micro': [0.7628, 0.7628, 0.7628, 0.7628, 0.7628],\n",
    "        'Precision weighted': [0.5829, 0.6687, 0.5819, 0.5819, 0.5819],\n",
    "        'Recall macro': [0.1429, 0.1440, 0.1429, 0.1429, 0.1429],\n",
    "        'Recall micro': [0.7628, 0.7628, 0.7628, 0.7628, 0.7628],\n",
    "        'Recall weighted': [0.7628, 0.7628, 0.7628, 0.7628, 0.7628],\n",
    "        'F1 macro': [0.1238, 0.1264, 0.1236, 0.1236, 0.1236],\n",
    "        'F1 micro': [0.7628, 0.7628, 0.7628, 0.7628, 0.7628],\n",
    "        'F1 weighted': [0.6608, 0.6633, 0.6602, 0.6602, 0.6602]\n",
    "       }\n",
    "\n",
    "df = pd.DataFrame(result_data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5caa8971",
   "metadata": {},
   "source": [
    "### Definition time to pick the best model \n",
    "\n",
    "Accuracy is a performance metric used to evaluate the performance of a classification model. It represents the percentage of correctly classified instances out of the total instances in the dataset. In other words, accuracy measures how often the model is correct in its predictions. It is calculated as the ratio of the number of correctly classified instances to the total number of instances in the dataset.\n",
    "\n",
    "Loss: Loss value indicates how well the model is performing during training. It is a numerical representation of the difference between the predicted outputs and the actual outputs. The lower the loss value, the better the model is at making accurate predictions.\n",
    "\n",
    "Precision: Precision measures how many of the predicted positive labels are actually correct. It is the proportion of true positives (TP) over the sum of true positives and false positives (FP). In other words, it answers the question: \"Out of all the predicted positive cases, how many are actually positive?\" A high precision score means that the model has a low false positive rate.\n",
    "\n",
    "Recall: Recall measures how many of the actual positive cases were correctly identified by the model. It is the proportion of true positives over the sum of true positives and false negatives (FN). In other words, it answers the question: \"Out of all the actual positive cases, how many did the model correctly identify as positive?\" A high recall score means that the model has a low false negative rate.\n",
    "\n",
    "F1 score: F1 score is the harmonic mean of precision and recall. It combines both measures and provides a more balanced evaluation of the model's performance. The F1 score is calculated as 2 * (precision * recall) / (precision + recall). It ranges from 0 to 1, where 1 represents the best possible performance and 0 represents the worst.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d21db8",
   "metadata": {},
   "source": [
    "### Soooo, I am clearly not an expert but something seems fishy to me. \n",
    "<pre> _\n",
    "<_><\n",
    "</pre>\n",
    "- Accuracy of all 5 models is the exact same ? \n",
    "- Models seem competent enough though\n",
    "- Precision and Recall are also identical thus F1 is the same\n",
    "- let's then pick the model with the lowest Loss value, which would be the charming <b> putrid-cormorant </b>\n",
    "    \n",
    "    https://huggingface.co/nicoco404/autotrain-aita-post-classifier-3535895495"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9083b73d",
   "metadata": {},
   "source": [
    "While I'm fetching fresh data to test this putrid model, let's launch the training of models on <i>Post Titles</i> since they are much shorter than <i>Post Contents</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bbbfa4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New post that has 100% NTA verdict\n",
    "prompt = \"\"\"\"recently, my friends and i went to a restaurant for dinner, where i noticed there was a cute waiter that was serving us. i told my friends, not thinking much of it. throughout the whole dinner, they proceeded to embarrass me about it, sometimes around the waiter, even asking to take a selfie with him. at the end of the dinner, while waiting for a friend to use the restroom, i noticed a friend of mine talking to the waiter 1v1, and i panicked, worried they'd embarrass me again but worse. i left (the bill was already paid for atp) and waited outside for them. they all come out smiling and laughing, saying they told the waiter i thought he was cute, and they got his number. i felt beyond embarrassed now. they put his number in my phone, and i said fuck it and sent a text. i wasn't expecting much to come out of this, so i was shocked to see him reply. we continued to talk throughout the night, even after my friends and i parted ways. the next morning, i was happy, the waiter and i were having a good conversation the same morning. later at lunch, my friend confessed that it wasnt the waiter that i was texting, it was my friend. my friend group was in on it, and even made a groupchat to laugh at me behind my back, leaking the messages and such. i was so mortified, they told me in front of most of our friend group (as i went to dinner with only 4 of them) i angrily left, sending a message to our discord server saying \"fuck you guys\" and went off on them. they thought i was upset at being catfished, and while i am somewhat upset, i was mainly upset for being turned into a joke and laughed at behind my back by people who i called friends. 2 of them were my best friends. some of them had said im overreacting, and some say im making it a bigger problem than it needs to be. my family says i should drop them, but idk what to do. some people say im right for being upset, and im not overreacting.\"\"\"\n",
    "\n",
    "# Loading access token for API\n",
    "with open('access_token', 'r') as f:\n",
    "    access_token = f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6af0f204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "009bb1679fc24160a86835ef04bd361a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.10k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f517fd139ed34328a42621c4ed1ed03e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/557M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f454fca072244aa3b2c150731e16bf2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/1.42k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba35a237f6824bf485efa08a6e15b26d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af18818d1e70464d83db8f0936f8837c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcabf59f99074c32838f6cac5bc3c583",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"tokenizer.json\";:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50232bfa6b7d4153b323c7849f3e7dfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/963 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"nicoco404/autotrain-aita-post-classifier-3535895495\", use_auth_token=access_token)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"nicoco404/autotrain-aita-post-classifier-3535895495\", use_auth_token=access_token)\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "outputs = model(**inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9ce60acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NTA: 81.39%\n",
      "YTA: 11.77%\n",
      "ESH: 3.23%\n",
      "NAH: 1.66%\n",
      "INFO: 1.08%\n",
      "YWBTA: 0.48%\n",
      "YWNBTA: 0.39%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "# Get the logits tensor\n",
    "outputs = model(**inputs)\n",
    "logits = outputs.logits\n",
    "\n",
    "# Map label indices to label names found in model config file\n",
    "# https://huggingface.co/nicoco404/autotrain-aita-post-classifier-3535895495/blob/main/config.json\n",
    "label_map = {\n",
    "    0: \"ESH\",\n",
    "    1: \"INFO\",\n",
    "    2: \"NAH\",\n",
    "    3: \"NTA\",\n",
    "    4: \"YTA\",\n",
    "    5: \"YWBTA\",\n",
    "    6: \"YWNBTA\"\n",
    "}\n",
    "\n",
    "# Apply softmax function to the logits so we get probability values\n",
    "probs = softmax(logits, dim=1)\n",
    "\n",
    "# Sort the labels and scores by descending score\n",
    "sorted_labels = sorted(label_map.values(), key=lambda x: probs[0][list(label_map.values()).index(x)].item(), reverse=True)\n",
    "sorted_scores = [f\"{probs[0][list(label_map.values()).index(label)].item() * 100:.2f}%\" for label in sorted_labels]\n",
    "\n",
    "# Print the sorted labels and scores\n",
    "for label, score in zip(sorted_labels, sorted_scores):\n",
    "    print(f\"{label}: {score}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e4e989",
   "metadata": {},
   "source": [
    "## That's so good !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f99366f",
   "metadata": {},
   "source": [
    "Before we try running more test data on our model, let's get back to our second batch of models trained on titles. Results are almost identical: \n",
    "Different input, same dataset ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5880d7c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model ID</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision macro</th>\n",
       "      <th>Precision micro</th>\n",
       "      <th>Precision weighted</th>\n",
       "      <th>Recall macro</th>\n",
       "      <th>Recall micro</th>\n",
       "      <th>Recall weighted</th>\n",
       "      <th>F1 macro</th>\n",
       "      <th>F1 micro</th>\n",
       "      <th>F1 weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>each-porpoise</td>\n",
       "      <td>0.7624</td>\n",
       "      <td>0.7628</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.7628</td>\n",
       "      <td>0.5819</td>\n",
       "      <td>0.1429</td>\n",
       "      <td>0.7628</td>\n",
       "      <td>0.7628</td>\n",
       "      <td>0.1236</td>\n",
       "      <td>0.7628</td>\n",
       "      <td>0.6602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>insubstantial-bear</td>\n",
       "      <td>0.7675</td>\n",
       "      <td>0.7628</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.7628</td>\n",
       "      <td>0.5819</td>\n",
       "      <td>0.1429</td>\n",
       "      <td>0.7628</td>\n",
       "      <td>0.7628</td>\n",
       "      <td>0.1236</td>\n",
       "      <td>0.7628</td>\n",
       "      <td>0.6602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fussy-nightingale</td>\n",
       "      <td>0.7740</td>\n",
       "      <td>0.7628</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.7628</td>\n",
       "      <td>0.5819</td>\n",
       "      <td>0.1429</td>\n",
       "      <td>0.7628</td>\n",
       "      <td>0.7628</td>\n",
       "      <td>0.1236</td>\n",
       "      <td>0.7628</td>\n",
       "      <td>0.6602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>incompatible-chimpanzee</td>\n",
       "      <td>0.7593</td>\n",
       "      <td>0.7628</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.7628</td>\n",
       "      <td>0.5819</td>\n",
       "      <td>0.1429</td>\n",
       "      <td>0.7628</td>\n",
       "      <td>0.7628</td>\n",
       "      <td>0.1236</td>\n",
       "      <td>0.7628</td>\n",
       "      <td>0.6602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chief-fish</td>\n",
       "      <td>0.7836</td>\n",
       "      <td>0.7628</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.7628</td>\n",
       "      <td>0.5819</td>\n",
       "      <td>0.1429</td>\n",
       "      <td>0.7628</td>\n",
       "      <td>0.7628</td>\n",
       "      <td>0.1236</td>\n",
       "      <td>0.7628</td>\n",
       "      <td>0.6602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model ID    Loss  Accuracy  Precision macro  \\\n",
       "0            each-porpoise  0.7624    0.7628            0.109   \n",
       "1       insubstantial-bear  0.7675    0.7628            0.109   \n",
       "2        fussy-nightingale  0.7740    0.7628            0.109   \n",
       "3  incompatible-chimpanzee  0.7593    0.7628            0.109   \n",
       "4               chief-fish  0.7836    0.7628            0.109   \n",
       "\n",
       "   Precision micro  Precision weighted  Recall macro  Recall micro  \\\n",
       "0           0.7628              0.5819        0.1429        0.7628   \n",
       "1           0.7628              0.5819        0.1429        0.7628   \n",
       "2           0.7628              0.5819        0.1429        0.7628   \n",
       "3           0.7628              0.5819        0.1429        0.7628   \n",
       "4           0.7628              0.5819        0.1429        0.7628   \n",
       "\n",
       "   Recall weighted  F1 macro  F1 micro  F1 weighted  \n",
       "0           0.7628    0.1236    0.7628       0.6602  \n",
       "1           0.7628    0.1236    0.7628       0.6602  \n",
       "2           0.7628    0.1236    0.7628       0.6602  \n",
       "3           0.7628    0.1236    0.7628       0.6602  \n",
       "4           0.7628    0.1236    0.7628       0.6602  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_title_model = {\n",
    "    'Model ID': ['each-porpoise', 'insubstantial-bear', 'fussy-nightingale', 'incompatible-chimpanzee', 'chief-fish'],\n",
    "    'Loss': [0.7624, 0.7675, 0.7740, 0.7593, 0.7836],\n",
    "    'Accuracy': [0.7628, 0.7628, 0.7628, 0.7628, 0.7628],\n",
    "    'Precision macro': [0.1090, 0.1090, 0.1090, 0.1090, 0.1090],\n",
    "    'Precision micro': [0.7628, 0.7628, 0.7628, 0.7628, 0.7628],\n",
    "    'Precision weighted': [0.5819, 0.5819, 0.5819, 0.5819, 0.5819],\n",
    "    'Recall macro': [0.1429, 0.1429, 0.1429, 0.1429, 0.1429],\n",
    "    'Recall micro': [0.7628, 0.7628, 0.7628, 0.7628, 0.7628],\n",
    "    'Recall weighted': [0.7628, 0.7628, 0.7628, 0.7628, 0.7628],\n",
    "    'F1 macro': [0.1236, 0.1236, 0.1236, 0.1236, 0.1236],\n",
    "    'F1 micro': [0.7628, 0.7628, 0.7628, 0.7628, 0.7628],\n",
    "    'F1 weighted': [0.6602, 0.6602, 0.6602, 0.6602, 0.6602],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data_title_model)\n",
    "df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "e4530e3f7a479c29f561e0bf57c489d52367e70e1e013d439943acccd42ec1e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
