{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "235cf72c",
   "metadata": {},
   "source": [
    "# Let's test out a zero-shot classification model on the data as is"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a7a6062f",
   "metadata": {},
   "source": [
    "This notebook is the next step after scrapping posts and comments from the subreddit r/AITA and analysing the data collected: <br />\n",
    "https://github.com/Nico404/scrap_reddit <br />\n",
    "https://github.com/Nico404/AITA_data_exploration_and_ML/blob/master/AITA_data_exploration.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b6170f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from transformers import pipeline\n",
    "import pprint\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dbae664e",
   "metadata": {},
   "source": [
    "Let's import our data from AITA_data_exploration.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e35189c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   post_id                                       post_content  \\\n",
      "0  10uxee0  I know this post sounds super petty, but this ...   \n",
      "1  10ur722  My daughter Bryn F9 is going on a trip to a ne...   \n",
      "2  10upxdd  Alright so my son (17) has weekly therapy appo...   \n",
      "3  10v2vra  We live three blocks away from my parents and ...   \n",
      "4  10ung90  My daughter (16) and I have gotten into a mass...   \n",
      "\n",
      "                                          post_title  \\\n",
      "0  AITA for telling my boyfriend I'll shave my le...   \n",
      "1  AITA for pulling my daughter from a waterpark ...   \n",
      "2  AITA for not letting an elderly woman have my ...   \n",
      "3  AITA for taking my kids to my parents house to...   \n",
      "4  AITA for calling my daughter a selfish insecur...   \n",
      "\n",
      "                                     comment_results  \n",
      "0  {'NTA': 31, 'YWBTA': 0, 'YWNBTA': 0, 'ESH': 0,...  \n",
      "1  {'NTA': 14, 'YWBTA': 0, 'YWNBTA': 0, 'ESH': 0,...  \n",
      "2  {'NTA': 27, 'YWBTA': 0, 'YWNBTA': 0, 'ESH': 0,...  \n",
      "3  {'NTA': 63, 'INFO': 1, 'YWBTA': 0, 'YWNBTA': 0...  \n",
      "4  {'NTA': 17, 'ESH': 3, 'YWBTA': 0, 'YWNBTA': 0,...  \n"
     ]
    }
   ],
   "source": [
    "with open('data/pickled_post_data.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "posts_df = pd.DataFrame(data)\n",
    "\n",
    "print(posts_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fce6ddb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's setup our transformer label candidates and load our model \n",
    "candidate_labels = [\"NTA\", \"YTA\", \"ESH\", \"NAH\", \"INFO\", \"YWBTA\", \"YWNBTA\"]\n",
    "candidate_labels_short = [\"NTA\", \"YTA\"]\n",
    "\n",
    "pipe = pipeline(model=\"facebook/bart-large-mnli\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8ff888bc",
   "metadata": {},
   "source": [
    "Let's run the zero-shot model on both Post content and Post title and compare it with the actual results we got from comments.\n",
    "Let's try and make a candidate shortlist also and add that to the mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "08a00c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "post content {'10uxee0': {'ESH': 0.19, 'INFO': 0.17, 'NAH': 0.17, 'YTA': 0.14, 'YWNBTA': 0.12, 'YWBTA': 0.11, 'NTA': 0.1}}\n",
      "post content short labels {'10uxee0': {'YTA': 0.57, 'NTA': 0.43}}\n",
      "post title {'10uxee0': {'INFO': 0.25, 'YTA': 0.2, 'NTA': 0.17, 'ESH': 0.13, 'NAH': 0.1, 'YWBTA': 0.08, 'YWNBTA': 0.07}}\n",
      "post title short labels {'10uxee0': {'YTA': 0.54, 'NTA': 0.46}}\n",
      "comment results {'10uxee0': {'NTA': 1.0, 'YWBTA': 0.0, 'YWNBTA': 0.0, 'ESH': 0.0, 'NAH': 0.0, 'INFO': 0.0, 'YTA': 0.0}}\n"
     ]
    }
   ],
   "source": [
    "all_posts_results = {}\n",
    "for i, row in posts_df.iterrows():\n",
    "    post_results = {}\n",
    "    post_content_prediction = pipe(row['post_content'], candidate_labels)\n",
    "    for label, score in zip(post_content_prediction[\"labels\"], post_content_prediction[\"scores\"]):\n",
    "        post_results[label] = round(score, 2)\n",
    "        all_posts_results[row['post_id']] = post_results\n",
    "    break\n",
    "\n",
    "all_posts_results_short = {}\n",
    "for i, row in posts_df.iterrows():\n",
    "    post_results = {}\n",
    "    post_content_prediction = pipe(row['post_content'], candidate_labels_short)\n",
    "    for label, score in zip(post_content_prediction[\"labels\"], post_content_prediction[\"scores\"]):\n",
    "        post_results[label] = round(score, 2)\n",
    "        all_posts_results_short[row['post_id']] = post_results\n",
    "    break\n",
    "\n",
    "all_post_title_results = {}\n",
    "for i, row in posts_df.iterrows():\n",
    "    post_title_results = {}\n",
    "    post_title_prediction = pipe(row['post_title'], candidate_labels)\n",
    "    for label, score in zip(post_title_prediction[\"labels\"], post_title_prediction[\"scores\"]):\n",
    "        post_title_results[label] = round(score, 2)\n",
    "        all_post_title_results[row['post_id']] = post_title_results\n",
    "    break\n",
    "\n",
    "all_post_title_results_short = {}\n",
    "for i, row in posts_df.iterrows():\n",
    "    post_title_results = {}\n",
    "    post_title_prediction = pipe(row['post_title'], candidate_labels_short)\n",
    "    for label, score in zip(post_title_prediction[\"labels\"], post_title_prediction[\"scores\"]):\n",
    "        post_title_results[label] = round(score, 2)\n",
    "        all_post_title_results_short[row['post_id']] = post_title_results\n",
    "    break\n",
    "\n",
    "all_comment_results = {}\n",
    "for i, row in posts_df.iterrows():\n",
    "    post_id = row['post_id']\n",
    "    comment_results = row['comment_results']\n",
    "    total_count = sum(comment_results.values())\n",
    "    probabilities = {key: value / total_count for key, value in comment_results.items()}\n",
    "    all_comment_results[post_id] = probabilities\n",
    "    break\n",
    "\n",
    "print(\"post content\", all_posts_results)\n",
    "print(\"post content short labels\", all_posts_results_short)\n",
    "print(\"post title\", all_post_title_results)\n",
    "print(\"post title short labels\", all_post_title_results_short)\n",
    "print(\"comment results\", all_comment_results)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "459bc535",
   "metadata": {},
   "source": [
    "For this one case:\n",
    "- similar results for both title and content on short-listed labels\n",
    "- unclear results on content vs title for this\n",
    "- all zero-shots have drastically different conclusions that the results we scrapped from comments\n",
    "\n",
    "Lets make functions and prettify the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9a251429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'10uxee0': {'ESH': 0.19, 'INFO': 0.17, 'NAH': 0.17, 'YTA': 0.14, 'YWNBTA': 0.12, 'YWBTA': 0.11, 'NTA': 0.1}, '10ur722': {'INFO': 0.25, 'NAH': 0.17, 'NTA': 0.17, 'YTA': 0.15, 'ESH': 0.12, 'YWNBTA': 0.07, 'YWBTA': 0.06}}\n",
      "{'10ur722': {'NTA': 0.53, 'YTA': 0.47}, '10uxee0': {'NTA': 0.43, 'YTA': 0.57}}\n",
      "{'10uxee0': {'INFO': 0.25, 'YTA': 0.2, 'NTA': 0.17, 'ESH': 0.13, 'NAH': 0.1, 'YWBTA': 0.08, 'YWNBTA': 0.07}, '10ur722': {'INFO': 0.21, 'YTA': 0.19, 'ESH': 0.15, 'NAH': 0.14, 'NTA': 0.13, 'YWNBTA': 0.1, 'YWBTA': 0.08}}\n",
      "{'10ur722': {'NTA': 0.4, 'YTA': 0.6}, '10uxee0': {'NTA': 0.46, 'YTA': 0.54}}\n",
      "{  '10upxdd': {  'ESH': 0.0,\n",
      "                 'INFO': 0.0,\n",
      "                 'NAH': 0.0,\n",
      "                 'NTA': 1.0,\n",
      "                 'YTA': 0.0,\n",
      "                 'YWBTA': 0.0,\n",
      "                 'YWNBTA': 0.0},\n",
      "   '10ur722': {  'ESH': 0.0,\n",
      "                 'INFO': 0.0,\n",
      "                 'NAH': 0.0,\n",
      "                 'NTA': 1.0,\n",
      "                 'YTA': 0.0,\n",
      "                 'YWBTA': 0.0,\n",
      "                 'YWNBTA': 0.0},\n",
      "   '10uxee0': {  'ESH': 0.0,\n",
      "                 'INFO': 0.0,\n",
      "                 'NAH': 0.0,\n",
      "                 'NTA': 1.0,\n",
      "                 'YTA': 0.0,\n",
      "                 'YWBTA': 0.0,\n",
      "                 'YWNBTA': 0.0}}\n"
     ]
    }
   ],
   "source": [
    "def get_predictions(dataframe, labels, prompt_type):\n",
    "    predictions = {}\n",
    "    for i, row in dataframe.iterrows():\n",
    "        post_results = {}\n",
    "        column_name = 'post_content' if prompt_type == 'content' else 'post_title'\n",
    "        post_prediction = pipe(row[column_name], labels)\n",
    "        post_results = {label: round(score, 2) for label, score in zip(post_prediction[\"labels\"], post_prediction[\"scores\"])}\n",
    "        predictions[row['post_id']] = post_results\n",
    "        if i == 5:\n",
    "            break\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def get_comment_results(dataframe):\n",
    "    comment_results = {}\n",
    "    for i, row in dataframe.iterrows():\n",
    "        post_id = row['post_id']\n",
    "        comment_results[post_id] = {key: value / sum(row['comment_results'].values()) for key, value in row['comment_results'].items()}\n",
    "        if i == 5:\n",
    "            break\n",
    "    return comment_results\n",
    "\n",
    "\n",
    "\n",
    "all_posts_results = get_predictions(posts_df, candidate_labels, 'content')\n",
    "all_posts_results_short = get_predictions(posts_df, candidate_labels_short, 'content')\n",
    "all_post_title_results = get_predictions(posts_df, candidate_labels, 'title')\n",
    "all_post_title_results_short = get_predictions(posts_df, candidate_labels_short, 'title')\n",
    "all_comments_results = get_comment_results(posts_df)\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=(len(all_posts_results)+1))\n",
    "print(all_posts_results)\n",
    "pp.pprint(all_posts_results_short)\n",
    "print(all_post_title_results)\n",
    "pp.pprint(all_post_title_results_short)\n",
    "print(all_comment_results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "e4530e3f7a479c29f561e0bf57c489d52367e70e1e013d439943acccd42ec1e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
